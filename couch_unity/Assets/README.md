## COUCH: Towards Controllable Human-Chair Interactions


[[Project Page](https://virtualhumans.mpi-inf.mpg.de/couch/)]
[[Paper](https://virtualhumans.mpi-inf.mpg.de/couch/zhang2022couch.pdf)]

![COUCH Examples](https://virtualhumans.mpi-inf.mpg.de/couch/couch_teaser.png)

## Description
This repository contains the training and run-time code for [COUCH](https://virtualhumans.mpi-inf.mpg.de/couch/). To access the COUCH Dataset, please visit [COUCH Dataset](https://virtualhumans.mpi-inf.mpg.de/couch/license.html).
The run-time Unity code is largly based on the code of [Neural State Machine](https://github.com/sebastianstarke/AI4Animation/tree/master/AI4Animation/SIGGRAPH_Asia_2019) by [Sebastian Starke](https://github.com/sebastianstarke). We appreciate the authors for open-sourcing their code.

## Running COUCH
We provide several demo scenes for testing COUCH. Note, the [Barracuda](https://stackoverflow.com/questions/68460374/cant-find-barracuda-package-in-unity-registry/) Library is a prerequisite for these demos.

### Motion Synthesis Testing
- Testing COUCH with a randomly sampled set of contact on a chair.
- Open the Demo Scene (Unity -> Assets -> Demo -> DemoTesting.unity).
- Hit the Play button.

### Hand Contact Prediction
- Demo for ContactNet - given any chair, to predict varied hand contacts.
- Open the ContactNet Scene (Unity -> Assets -> DemoContact -> Demo.unity).
- Hit the Play button.
- You will see different sets of hand contacts generated by ContactNet for the different objects in the scene.


### Motion Synthesis Sampling Mode 
- The sampling mode of COUCH requires the inference of ContactNet, PoseNet, and ControlNet.
- Open the Demo Scene (Unity -> Assets -> Demo -> DemoSampling.unity).
- Hit the Play button.
- Press N to fix contact and synthesise the full motion sequence.



## Exporting Training Data
### PoseNet Data
You can download PoseNet Data and the raw `fbx` files from [COUCH Dataset](https://virtualhumans.mpi-inf.mpg.de/couch/license.html/). However, in case you want to export the data from Unity:
- Open the Mocap Scene (Unity -> Assets -> MotionCapture -> Scene.unity).
- Click on the Editor game object in the scene hierarchy window.
- Open the PoseNet Exporter (Header -> AI4Animation -> PoseNet Exporter).
- Choose wheather you want to export train or test data.
- Click `Reload`
- Click `Export`

### ControlNet Data
You can download ContactNet Data from [COUCH Dataset](https://virtualhumans.mpi-inf.mpg.de/couch/license.html/). However, in case you want to export the data from Unity:
- Open the Mocap Scene (Unity -> Assets -> MotionCapture -> Scene.unity).
- Open the Motion Exporter (Header -> AI4Animation -> ControlNet Exporter).
- Click `Reload`
- Click `Export`


## Note
In the demo, there will be many corner cases where the system may fail due to the exponential combinatorial amount of possible actions and interactions of the character with the environment.


## License
By using this code, you agree to adhere with the liscense of [AI4Animation](https://github.com/sebastianstarke/AI4Animation#copyright-information). In addition:

1.	You may use, reproduce, modify, and display the research materials provided under this license (the “Research Materials”) solely for noncommercial purposes. Noncommercial purposes include academic research, teaching, and testing, but do not include commercial licensing or distribution, development of commercial products, or any other activity which results in commercial gain. You may not redistribute the Research Materials.
2.	You agree to (a) comply with all laws and regulations applicable to your use of the Research Materials under this license, including but not limited to any import or export laws; (b) preserve any copyright or other notices from the Research Materials; and (c) for any Research Materials in object code, not attempt to modify, reverse engineer, or decompile such Research Materials except as permitted by applicable law.
3.	THE RESEARCH MATERIALS ARE PROVIDED “AS IS,” WITHOUT WARRANTY OF ANY KIND, AND YOU ASSUME ALL RISKS ASSOCIATED WITH THEIR USE. IN NO EVENT WILL ANYONE BE LIABLE TO YOU FOR ANY ACTUAL, INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES ARISING OUT OF OR IN CONNECTION WITH USE OF THE RESEARCH MATERIALS.

## Citation
If you find this Model & Software useful in your research we would kindly ask you to cite:
```
@inproceedings{zhang2022couch,
      title = {COUCH: Towards Controllable Human-Chair Interactions},
      author = {Zhang, Xiaohan and Bhatnagar, Bharat Lal and Starke, Sebastian and Guzov, Vladimir and Pons-Moll, Gerard},
      booktitle = {European Conference on Computer Vision ({ECCV})},
      month = {October},
      organization = {{Springer}},
      year = {2022}
}